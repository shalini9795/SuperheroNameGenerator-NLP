{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Superhero Name Generator - Learner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shalini9795/SuperheroNameGenerator-NLP/blob/main/Superhero_Name_Generator_Learner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21XXWP7Fpt2L"
      },
      "source": [
        "# Superhero (and Supervillain) Name Generator\n",
        "\n",
        "---\n",
        "\n",
        "[Superhero Names Dataset](https://github.com/am1tyadav/superhero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6P0NU5Cpt2R"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "1. Import the data\n",
        "2. Create a tokenizer\n",
        "3. Char to index and Index to char dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srULhalZpt2M",
        "outputId": "6cddd272-963e-4d4e-d25b-c52cb15bbfc4"
      },
      "source": [
        "!git clone https://github.com/am1tyadav/superhero"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'superhero'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uq4CLmsLpt2P",
        "outputId": "a09f375e-fe9e-47fe-f17a-de8537b8c045"
      },
      "source": [
        "with open('superhero//superheroes.txt','r') as f:\n",
        "  data=f.read()\n",
        "\n",
        "data[:100]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jumpa\\t\\ndoctor fate\\t\\nstarlight\\t\\nisildur\\t\\nlasher\\t\\nvarvara\\t\\nthe target\\t\\naxel\\t\\nbattra\\t\\nchangeling\\t\\npyrrh'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqhtLuAHpt2R",
        "outputId": "50ba451f-c00c-4068-acd0-07885e79ef79"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz8yBgZ_uWSy"
      },
      "source": [
        "We do not want to filter out the \\ts in the text hence we are using filter to filter out all the other characters except \\t\\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Lo1Yqzpt2T"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~',\n",
        "    split='\\n',\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3yA54KXuPdh"
      },
      "source": [
        "Convert sequence of characters to sequence of numbers for the machine to understand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYfC4sj2pt2V"
      },
      "source": [
        "tokenizer.fit_on_texts(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylexFBuKupmC"
      },
      "source": [
        "Build vocabulary, whenever tokenizers gets 'a' it will assign it a numeric value of 2, \n",
        "---\n",
        "Why is it important?\n",
        "---\n",
        "\n",
        "Our neural network model does not understand characters but it does understand numbers\n",
        "\n",
        "Therefore we have creates a tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO4-dPM6pt2X",
        "outputId": "5abf4000-ec00-4cac-f428-d2c856d01b5d"
      },
      "source": [
        "char_to_index = tokenizer.word_index\n",
        "index_to_char = dict((v,k) for k,v in char_to_index.items())\n",
        "\n",
        "print(\"printing contents of index_to_char\", index_to_char)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "printing contents of index_to_char {1: '\\t', 2: 'a', 3: 'e', 4: 'r', 5: 'o', 6: 'n', 7: 'i', 8: ' ', 9: 't', 10: 's', 11: 'l', 12: 'm', 13: 'h', 14: 'd', 15: 'c', 16: 'u', 17: 'g', 18: 'k', 19: 'b', 20: 'p', 21: 'y', 22: 'w', 23: 'f', 24: 'v', 25: 'j', 26: 'z', 27: 'x', 28: 'q'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMwtIw_Bpt2Z"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "1. Converting between names and sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7iQLIXzpt2a",
        "outputId": "95e508a1-5795-4fe9-a3f1-2b467a6663a3"
      },
      "source": [
        "names = data.splitlines() #splitting by \\n\n",
        "names[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jumpa\\t',\n",
              " 'doctor fate\\t',\n",
              " 'starlight\\t',\n",
              " 'isildur\\t',\n",
              " 'lasher\\t',\n",
              " 'varvara\\t',\n",
              " 'the target\\t',\n",
              " 'axel\\t',\n",
              " 'battra\\t',\n",
              " 'changeling\\t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_-TTfqipt2c",
        "outputId": "004f4548-b586-45ab-a6b3-5b01433ede71"
      },
      "source": [
        "tokenizer.texts_to_sequences(names[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25], [16], [12], [20], [2], [1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6IsKH1Upt2e"
      },
      "source": [
        "def name_to_seq(name):\n",
        "  return [tokenizer.texts_to_sequences(c)[0][0] for c in name]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrm5X2lqyM2Z"
      },
      "source": [
        "In this function we have conerted list of lists to a single list i.e [ [25], [16], [12], [20], \n",
        "[2], [1] ] to [25, 16, 12, 20, 2, 1] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuLUiMP3pt2g",
        "outputId": "468e2eb7-994f-4b56-c417-769991d22172"
      },
      "source": [
        "name_to_seq(names[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 16, 12, 20, 2, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFUYhimKpt2h"
      },
      "source": [
        "def seq_to_name(seq):\n",
        "  return ''.join([index_to_char[i] for i in seq if i!=0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ROhCqmhLpt2k",
        "outputId": "8ae3cbf7-6c5a-47d7-a8cc-8a50b7cda3d9"
      },
      "source": [
        "seq_to_name(name_to_seq(names[0])) #getting the sequence back helper functions"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jumpa\\t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCbAzsNjpt2m"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "1. Creating sequences\n",
        "2. Padding all sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstNn-0dpt2m"
      },
      "source": [
        "sequences= []\n",
        "\n",
        "for name in names:\n",
        "  seq=name_to_seq(name)\n",
        "  if len(seq) >= 2:\n",
        "    sequences += [seq[:i] for i in range(2,len(seq)+1)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATaepOwtYm2_"
      },
      "source": [
        "We are getting sequences for each word, dividing each word into 2 first and gradually adding the next letter it needs to remember after the first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjRTMysvpt2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f82150-8da6-4d48-8333-c484dd5032a0"
      },
      "source": [
        "sequences[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25, 16],\n",
              " [25, 16, 12],\n",
              " [25, 16, 12, 20],\n",
              " [25, 16, 12, 20, 2],\n",
              " [25, 16, 12, 20, 2, 1],\n",
              " [14, 5],\n",
              " [14, 5, 15],\n",
              " [14, 5, 15, 9],\n",
              " [14, 5, 15, 9, 5],\n",
              " [14, 5, 15, 9, 5, 4]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR68pu2tpt2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bce4d97-2c49-4d5e-b5af-d3c9389e2fbf"
      },
      "source": [
        "max_len = max([len(x) for x in sequences])\n",
        "print(max_len)\n",
        "#tokenizer starts with 1 and not with 0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_1BtWO7pt2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa0775e-42b0-416e-b812-4893509853ff"
      },
      "source": [
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences,padding = 'pre',\n",
        "    maxlen=max_len\n",
        ")\n",
        "#pad 0s before each so that o make it of even length\n",
        "#we have not done it after because it will be easier to recognize the labels\n",
        "print(padded_sequences[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0 25 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPlrLRpSpt2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e690a0d2-4d7d-49c7-e1ba-639ccdc4e48d"
      },
      "source": [
        "padded_sequences.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88279, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLg_asHynuV3"
      },
      "source": [
        "## Task 5: Creating Training and Validation Sets\n",
        "\n",
        "1. Creating training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE4BIeSnpt2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7c286b-c510-48f7-cb35-2c91223c147d"
      },
      "source": [
        "x,y=padded_sequences[:,:-1],padded_sequences[:,-1]\n",
        "print(x.shape,y.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88279, 32) (88279,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knMVMtJecnvv",
        "outputId": "38593e21-f49e-4429-e535-3206dc9f08db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66209, 32) (66209,)\n",
            "(22070, 32) (22070,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFDrYWUtnuV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cc81e7-dc64-4700-997c-819338284f09"
      },
      "source": [
        "num_chars = len(char_to_index.keys())+1 #one because we have added 0s\n",
        "print(num_chars)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgqRZtqnpt2x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTceVGMInuV4"
      },
      "source": [
        "## Task 6: Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3dKOaeCeM5Y"
      },
      "source": [
        "pass the number of characters as the first argument because that is the size of the vocabulary that we have\n",
        "\n",
        "---\n",
        "8 is the dimension of the future vector not taking large values because maxlen is 30\n",
        "\n",
        "Why are we using causal padding- (output t does not depend on t+1, temporal order is not going to be violated, causal good for time series data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHr2KEUgnuV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5735f380-9cab-4a90-8fe5-bcc7d82d9468"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPool1D, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional, Dense\n",
        "\n",
        "model=Sequential([\n",
        "                  Embedding(num_chars, 8, input_length=max_len-1),\n",
        "                  Conv1D(64,5,strides=1,activation='tanh', padding='causal'),\n",
        "                  MaxPool1D(2),\n",
        "                  LSTM(32),\n",
        "                  Dense(num_chars, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 32, 8)             232       \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 32, 64)            2624      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 29)                957       \n",
            "=================================================================\n",
            "Total params: 16,229\n",
            "Trainable params: 16,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xwnwiKnuV4"
      },
      "source": [
        "## Task 7: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Ssl4qupt22"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNWX6FPOnuV5"
      },
      "source": [
        "## Task 8: Generate Names!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f50aTRcpt24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQ0FInlpt26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}